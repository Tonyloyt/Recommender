{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Table of Content :**\n",
    "1. **[Load the data](#section1)**\n",
    "\n",
    "\n",
    "2. **[Preprocessing](#section2)**\n",
    "    * 2-1. Subsampling\n",
    "    * 2-2. Assign new Id values to Users and Movies\n",
    "    * 2-3. Split the data into train & test set\n",
    "    * 2-4. Creat looking-up dictionaries for users, movies and ratings\n",
    "  \n",
    "\n",
    "3. **[User-User Collaborative Filtering](#section3)**\n",
    "    * 3-1. Count the number of users and movies\n",
    "    * 3-2. Get the averages, deviations and the weights\n",
    "    * 3-3. Predict the ratings\n",
    "    \n",
    "  \n",
    "4. **[Item-Item Collaborative Filtering](#section4)**\n",
    "    * 4-1. Get the averages, deviations and the weights\n",
    "    * 4-3. Predict the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "from sortedcontainers import SortedList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data <a id = 'section1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-12-25 15:26:09</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-11-27 08:19:02</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-06-23 20:36:14</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-10-28 13:29:44</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp           title  \\\n",
       "0       1        2     3.5  2005-04-02 23:53:47  Jumanji (1995)   \n",
       "1       5        2     3.0  1996-12-25 15:26:09  Jumanji (1995)   \n",
       "2      13        2     3.0  1996-11-27 08:19:02  Jumanji (1995)   \n",
       "3      29        2     3.0  1996-06-23 20:36:14  Jumanji (1995)   \n",
       "4      34        2     3.0  1996-10-28 13:29:44  Jumanji (1995)   \n",
       "\n",
       "                       genres  \n",
       "0  Adventure|Children|Fantasy  \n",
       "1  Adventure|Children|Fantasy  \n",
       "2  Adventure|Children|Fantasy  \n",
       "3  Adventure|Children|Fantasy  \n",
       "4  Adventure|Children|Fantasy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = '../'\n",
    "rt = pd.read_csv(dir + 'data/rating.csv')\n",
    "mo = pd.read_csv(dir + 'data/movie.csv')\n",
    "\n",
    "# Joing the two data frame\n",
    "df = pd.merge(rt, mo, how = 'inner', on = ['movieId'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        2     3.5\n",
       "1       5        2     3.0\n",
       "2      13        2     3.0\n",
       "3      29        2     3.0\n",
       "4      34        2     3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = ['timestamp', 'title', 'genres'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing <a id = 'section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Sub-sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       0        2     3.5\n",
       "1       4        2     3.0\n",
       "2      12        2     3.0\n",
       "3      28        2     3.0\n",
       "4      33        2     3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the user Id starts from 0 \n",
    "df.userId -= 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples of the data is  20000263\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of samples of the data is \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract only the useful subset data whose users and movies have many ranting data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Users is  138493\n",
      "The number of Movies is  26745\n"
     ]
    }
   ],
   "source": [
    "N = df.userId.max() + 1\n",
    "M = df.movieId.nunique() + 1\n",
    "\n",
    "print(\"The number of Users is \", N)\n",
    "print(\"The number of Movies is \", M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_count = Counter(df.userId)\n",
    "movie_ids_count = Counter(df.movieId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome of `Counter()` will be **'column value : count_number'**. So take only the column values from the most common ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the numbers to subset \n",
    "n = 1000\n",
    "m = 200 \n",
    "\n",
    "user_ids = [col for col, idx in user_ids_count.most_common(n)]\n",
    "movie_ids = [col for col, idx in movie_ids_count.most_common(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data only with the user id and movie id mostly rated\n",
    "df_sub = df[df.userId.isin(user_ids) & df.movieId.isin(movie_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>571</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>585</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>740</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>767</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating\n",
       "20      155        2     5.0\n",
       "85      571        2     3.5\n",
       "89      585        2     3.0\n",
       "123     740        2     3.0\n",
       "129     767        2     3.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Assign new Id values to Users and Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are sparsity in the values of `userId` and `movieID`. Create the new ids for users and movies in the `df_sub` DataFrame.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic = {}\n",
    "i = 0\n",
    "\n",
    "for k in user_ids:\n",
    "    user_dic[k] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dic = {}\n",
    "i = 0\n",
    "\n",
    "for k in movie_ids:\n",
    "    movie_dic[k] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjone\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\jjone\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>movie_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>190</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>571</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>849</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>585</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>661</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>740</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>767</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>348</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  user_idx  movie_idx\n",
       "0     155        2     5.0       190        125\n",
       "1     571        2     3.5       849        125\n",
       "2     585        2     3.0       661        125\n",
       "3     740        2     3.0       176        125\n",
       "4     767        2     3.0       348        125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['user_idx'] = df_sub.userId.apply(lambda x: user_dic[x])\n",
    "df_sub['movie_idx'] = df_sub.movieId.apply(lambda x: movie_dic[x])\n",
    "\n",
    "df_sub = df_sub.reset_index(drop = True)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Split the data into train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "df_sub = shuffle(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "cut = int(0.8*len(df_sub))\n",
    "\n",
    "tr = df_sub.iloc[:cut]\n",
    "te = df_sub.iloc[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index for each dataset \n",
    "tr = tr.reset_index(drop = True)\n",
    "te = te.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train :  133628\n",
      "The size of test :  33407\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of train : \", len(tr))\n",
    "print(\"The size of test : \", len(te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Creat looking-up dictionaries for users, movies and ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries for eaily looking up user_ids, movies_ids and ratings. \n",
    "\n",
    "|        Name       |               Forms              | \n",
    "|-------------------|:--------------------------------:|\n",
    "| **user_to_movie** |       *{user_id : movie_id}*     |\n",
    "| **movie_to_user** |       *{movie_id : user_id}*     |\n",
    "| **um_to_rating**  | *{(user_id, movie_id) : rating}* |\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_movie = {}\n",
    "movie_to_user = {}\n",
    "um_to_rating_tr = {}\n",
    "count = 0\n",
    "\n",
    "# Create user, movie look-up dictionary with train set\n",
    "def making_user_movie_dics_train(row):\n",
    "\n",
    "    global count\n",
    "\n",
    "    a = int(row.user_idx)    # The user id of the given row\n",
    "    m = int(row.movie_idx)   # Tue movie id of the given row\n",
    "    r = row.rating           # The rating that the user gave to the movie\n",
    "\n",
    "    # Fill the \"user to movie\" dict\n",
    "    if a not in user_to_movie:\n",
    "        user_to_movie[a] = [m]\n",
    "    else:\n",
    "        user_to_movie[a].append(m)\n",
    "\n",
    "    # Fill the \"movie to user\" dict\n",
    "    if m not in movie_to_user:\n",
    "        movie_to_user[m] = [a]\n",
    "    else:\n",
    "        movie_to_user[m].append(a)\n",
    "\n",
    "    # Fill the \"(user, movie) to rating\" dict\n",
    "    um_to_rating_tr[(a, m)] = r\n",
    "    \n",
    "    count += 1\n",
    "    if count % 10000 == 0:\n",
    "        print(\"==========Processed: %.2f\" % (count/len(tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Processed: 0.07\n",
      "==========Processed: 0.15\n",
      "==========Processed: 0.22\n",
      "==========Processed: 0.30\n",
      "==========Processed: 0.37\n",
      "==========Processed: 0.45\n",
      "==========Processed: 0.52\n",
      "==========Processed: 0.60\n",
      "==========Processed: 0.67\n",
      "==========Processed: 0.75\n",
      "==========Processed: 0.82\n",
      "==========Processed: 0.90\n",
      "==========Processed: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Apply the function\n",
    "_ = tr.apply(making_user_movie_dics_train, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As test set has no ratings (we're predicting it), it has to be processed without rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user, movie look-up dictionary with test set\n",
    "um_to_rating_te = {}\n",
    "count = 0\n",
    "\n",
    "def making_user_movie_dics_test(x):\n",
    "\n",
    "    global count\n",
    "\n",
    "    a = int(x.user_idx)\n",
    "    m = int(x.movie_idx)\n",
    "    r = x.rating\n",
    "\n",
    "    # Fill the \"(user, movie) to rating\" dict\n",
    "    um_to_rating_te[(a, m)] = r\n",
    "        \n",
    "    count += 1\n",
    "    if count % 10000 == 0:\n",
    "        print(\"==========Processed: %.2f\" % (count/len(te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Processed: 0.30\n",
      "==========Processed: 0.60\n",
      "==========Processed: 0.90\n"
     ]
    }
   ],
   "source": [
    "_ = te.apply(making_user_movie_dics_test, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. User-User Collaborative Filtering <a id = 'section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-User collaborative filtering is getting the similarites of users and provide the recommendation with the movies that the users with similar taste liked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Score(a, m) = \\bar{r}$<sub>a</sub> + $\\sum_{b=1}^{N} W$<sub>a_b</sub> * ($r$<sub>b_m</sub> - $\\bar{r}$<sub>b</sub>) $/$ $\\sum_{b=1}^{N} |W$<sub>a_b</sub>$|$ \n",
    "\n",
    "- $\\bar{r}$<sub>a</sub> : the average rating of user a \n",
    "- W<sub>a_b</sub> : the similarities between user a & b\n",
    "- ($r$<sub>b_m</sub> - $\\bar{r}$<sub>b</sub>) : the rating deviation of the user b to the movie m "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Count the number of users and movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of users\n",
    "N = np.max(list(user_to_movie.keys())) + 1                               # User id starts from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of movies\n",
    "m_tr = np.max(list(movie_to_user.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum movie id from the test set for the movies not in the train set\n",
    "te_movie_list = [m for (u, m), r in um_to_rating_te.items()]\n",
    "m_te = np.max(te_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data: 1000 users & 200 movies\n"
     ]
    }
   ],
   "source": [
    "# Total Number of movies both from train & test\n",
    "M = max(m_tr, m_te) + 1\n",
    "\n",
    "print(\"The size of the data: {} users & {} movies\".format(N, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Get the averages, deviations and the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the average and deviation of ratings for each user and the similarities between users. Terms to be calculated as follows:\n",
    "\n",
    "|        Name       |               Values              |      Final Outcome   |\n",
    "|:-------------------:|:--------------------------------:|-------------------------------:|\n",
    "|      **r_avg**    |the average rating for each user| the list of averages (**averages**) |\n",
    "|    **r_dev_dic**  |the deviation of rating for each user and movie| the list of deviations (**deviations**)  |\n",
    "|      **w_ab**     | the similarities between user a and b| the list of neighbors with the weights (**neigbors**)  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 25                  # the number of neights to consider\n",
    "similarity_limit = 5    # the minimum number of movies users must have in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "averages = []           # ----> the list of averages\n",
    "deviations = []         # ----> the list of deviations\n",
    "neighbors = []          # ----> the list of neighbors with the weights\n",
    "\n",
    "for a in range(N):\n",
    "    \n",
    "    # Get the movie lists rated by user a\n",
    "    movies_a = user_to_movie[a]\n",
    "    \n",
    "    # Create the set of the movies to get the common movie list with user b\n",
    "    movies_a_set = set(movies_a)\n",
    "\n",
    "    # Create the \"movie : rating\" dictionary and get the rating average by user a\n",
    "    r_dic_a = { m : um_to_rating_tr[(a, m)] for m in movies_a }\n",
    "    r_avg_a = np.mean(list(r_dic_a.values()))                           # average rating of user a\n",
    "\n",
    "    # Create the \"movie : rating deviation\" dictionary and get the deviation by user a\n",
    "    r_dev_dic_a = { m : (r - r_avg_a) for m, r in r_dic_a.items() }\n",
    "    r_dev_arr_a = np.array(list(r_dev_dic_a.values()))\n",
    "    r_sigma_a = np.sqrt(np.dot(r_dev_arr_a, r_dev_arr_a))                # for calculating the user similarities\n",
    "\n",
    "    # Save the average and deviation value\n",
    "    averages.append(r_avg_a)\n",
    "    deviations.append(r_dev_arr_a)\n",
    "\n",
    "    w_neighbor = SortedList()\n",
    "    for b in range(N):\n",
    "        if b != a:\n",
    "            \n",
    "            # Get the movie lists rated by user b\n",
    "            movies_b = user_to_movie[b]\n",
    "\n",
    "            # Create the set of the movies to get the common movie list with user b\n",
    "            movies_b_set = set(movies_b)\n",
    "            movies_a_b = (movies_a_set & movies_b_set)                   # common movies by user a & b (Intersection)\n",
    "\n",
    "            # Get the rating average and deviation by the other users whose similarities are above the limit\n",
    "            if len(movies_a_b) > similarity_limit:\n",
    "\n",
    "                # Create the \"movie : rating\" dictionary and get the rating average by user b\n",
    "                r_dic_b = { m : um_to_rating_tr[(b, m)] for m in movies_b }\n",
    "                r_avg_b = np.mean(list(r_dic_b.values()))                    # average rating of user b\n",
    "\n",
    "                # Create the \"movie : rating deviation\" dictionary and get the deviation by user b\n",
    "                r_dev_dic_b = { m : (r - r_avg_b) for m, r in r_dic_b.items() }\n",
    "                r_dev_arr_b = np.array(list(r_dev_dic_b.values()))\n",
    "                r_sigma_b = np.sqrt(np.dot(r_dev_arr_b, r_dev_arr_b))    # for calculating the user similarities\n",
    "\n",
    "                # User similarities ( <- correlation weights)\n",
    "                numerator = sum(r_dev_dic_a[m] * r_dev_dic_b[m] for m in movies_a_b)\n",
    "                w_ab = numerator / (r_sigma_a * r_sigma_b)\n",
    "\n",
    "                # Add to the sorted list (negative weights for descending)\n",
    "                w_neighbor.add((-w_ab, b))\n",
    "\n",
    "                # If the number of neighbors is obove the limit K, delete the last one\n",
    "                if len(w_neighbor) > K:\n",
    "                    del w_neighbor[-1]\n",
    "\n",
    "    # Save the neightbor\n",
    "    neighbors.append(w_neighbor)\n",
    "\n",
    "    if a % 100 == 0:\n",
    "        print(a)            # tracking the preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Predict the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scoring function \n",
    "def predict_scoring(a, m):\n",
    "    '''\n",
    "    Predicting the rating of user a to movie b\n",
    "    input : user_id (a) and movie_id (m)\n",
    "    output : the predicted rating\n",
    "    '''\n",
    "    # Initialization\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for w_ab, b in neighbors[a]:\n",
    "        try:\n",
    "            w_ab *= -1\n",
    "            numerator += w_ab * deviations[b][m]\n",
    "            denominator += abs(w_ab)\n",
    "\n",
    "        # For the case that the neighbors of user a didn't rate the given movie m\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # If the sum of weights is 0 (the sum of the similarities values = 0)\n",
    "    if denominator == 0:\n",
    "        pred = averages[a]\n",
    "    else:\n",
    "        pred = averages[a] + numerator / denominator\n",
    "\n",
    "    # The fixed range of rating is between .5 and 5\n",
    "    pred = min(5, pred)\n",
    "    pred = max(.5, pred)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the get_loss function \n",
    "def get_loss(pred, actual):\n",
    "    '''\n",
    "    Calculating the loss by MSE\n",
    "    input: the list of the prediction and actual values\n",
    "    output : mean_squared_error\n",
    "    '''\n",
    "    loss = np.array(pred) - np.array(actual)\n",
    "    return np.mean(loss**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction and actual value from train set\n",
    "tr_preds = []\n",
    "tr_actual = []\n",
    "\n",
    "for (a, m), r in um_to_rating_tr.items():\n",
    "    # Predict the score of movie m by user a\n",
    "    pred = predict_scoring(a, m)\n",
    "\n",
    "    tr_preds.append(pred)\n",
    "    tr_actual.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction and actual value from test set\n",
    "te_preds = []\n",
    "te_actual = []\n",
    "\n",
    "for (a, m), r in um_to_rating_te.items():\n",
    "    # Predict the score of movie m by user a\n",
    "    pred = predict_scoring(a, m)\n",
    "\n",
    "    te_preds.append(pred)\n",
    "    te_actual.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of train set : 0.8552\n",
      "The loss of test set :  0.8746\n"
     ]
    }
   ],
   "source": [
    "# Get the loss\n",
    "tr_loss = get_loss(tr_preds, tr_actual)\n",
    "te_loss = get_loss(te_preds, te_actual)\n",
    "\n",
    "print(\"The loss of train set : %.4f\" % tr_loss)\n",
    "print(\"The loss of test set :  %.4f\" % te_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Item-Item Collaborative Filtering <a id = 'section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item-Item collaborative filtering is getting the similarites of items and provide the recommendation with the simiiar items that the given user would like. This can be thought in an opposite way of User-User collaborative filtering and the whole process is the same. Flip the original *User_to_Movie* matrix to *Movie_to_User* matrix. Imagine the items give ratings to users and **find the users the items would prefer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pratical difference is the number of data for computing. When comparing between items, there are much more data than comparing between users (up to ~ 100k users **vs.** up to ~ 20k items to look up). Therefore, the item-based CF can have the weighted values based on more data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus, calculating scores require $M^2*N$ times while for user-based CF, $N^2*M$. Considering N >> M, it's easy to understand that the item-based CF is faster than user-based CF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Get the averages, deviations and the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|        Name       |               Values              |      Final Outcome   |\n",
    "|-------------------|--------------------------------|-------------------------------:|\n",
    "|      **r_avg**    |the average rating for each user| the list of averages (**averages**) |\n",
    "|    **r_dev_dic**  |the deviation of rating for each user and movie| the list of deviations (**deviations**)  |\n",
    "|      **w_mn**     | the similarities between movie a and b| the list of neighbors with the weights (**neigbors**)  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20                  # the number of neights to consider\n",
    "similarity_limit = 5    # the minimum number of movies users must have in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = []           # ----> the list of averages\n",
    "deviations = []         # ----> the list of deviations\n",
    "neighbors = []          # ----> the list of neighbors with the weights\n",
    "\n",
    "for m in range(M):\n",
    "\n",
    "    # Get the user lists who rated movie m \n",
    "    users_m = movie_to_user[m]\n",
    "\n",
    "    # Create the set of the users to get the common user list with movie n \n",
    "    users_m_set = set(users_m)\n",
    "\n",
    "    # Create the \"user : rating\" dictionary and get the rating average to the movie m \n",
    "    r_dic_m = { a : um_to_rating_tr[(a, m)] for a in users_m }\n",
    "    r_avg_m = np.mean(list(r_dic_m.values()))                                   # average rating of the movie m\n",
    "\n",
    "    # Create the \"user : rating deviation\" dictionary and get the deviation to the movie m\n",
    "    r_dev_dic_m = { a : (r - r_avg_m) for a, r in r_dic_m.items() }             # how the user ratings deviate about the movie m \n",
    "    r_dev_arr_m = np.array(list(r_dev_dic_m.values()))\n",
    "    r_sigma_m = np.sqrt(np.dot(r_dev_arr_m, r_dev_arr_m))                       # for calculating the movie similarities\n",
    "\n",
    "    # Save the average and deviation value \n",
    "    averages.append(r_avg_m)\n",
    "    deviations.append(r_dev_arr_m)\n",
    "\n",
    "    w_neighbor = SortedList()\n",
    "    for n in range(M):\n",
    "        if n != m:\n",
    "\n",
    "            # Get the user lists rated by movie n\n",
    "            users_n = movie_to_user[n]\n",
    "\n",
    "            # Create the set of the users to get the common user list with movie n\n",
    "            users_n_set = set(users_n)\n",
    "            users_m_n = (users_m_set & users_n_set)                             # common users by movie m & n (Intersection)\n",
    "\n",
    "            # Get the rating average and deviation of the other movies whose similarities are above the limit\n",
    "            if len(users_m_n) > similarity_limit:\n",
    "\n",
    "                # Create the \"user : rating\" dictionary and get the rating average by movie n\n",
    "                r_dic_n = { a : um_to_rating_tr[(a, n)] for a in users_n }\n",
    "                r_avg_n = np.mean(list(r_dic_n.values()))                       # average rating to the movie n\n",
    "\n",
    "                # Create the \"user : rating deviation\" dictionary and get the deviation to the movie n\n",
    "                r_dev_dic_n = { a : (r - r_avg_n) for a, r in r_dic_n.items() }\n",
    "                r_dev_arr_n = np.array(list(r_dev_dic_n.values()))\n",
    "                r_sigma_n = np.sqrt(np.dot(r_dev_arr_n, r_dev_arr_n))           # for calculating the movie similarities\n",
    "\n",
    "                # movie similarities (Pearson correlation)\n",
    "                numerator = sum(r_dev_dic_m[a] * r_dev_dic_n[a] for a in users_m_n)\n",
    "                w_mn = numerator / (r_sigma_m * r_sigma_n)\n",
    "\n",
    "                # Add to the sorted list (negative weights for descending)\n",
    "                w_neighbor.add((-w_mn, n))\n",
    "\n",
    "                # If the number of neighbors is obove the limit K, delete the last one\n",
    "                if len(w_neighbor) > K:\n",
    "                    del w_neighbor[-1]\n",
    "\n",
    "    # Save the neightbor\n",
    "    neighbors.append(w_neighbor)\n",
    "\n",
    "    if a % 100 == 0:\n",
    "        print(\"==========Processed: {}%\".format(a//N))            # tracking the preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Predict the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scoring(a, m):\n",
    "    '''\n",
    "    Predicting the rating of user a to movie b\n",
    "    input : user_id (a) and movie_id (m)\n",
    "    output : the predicted rating\n",
    "    '''\n",
    "    # Initialization\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    for w_mn, n in neighbors[m]:\n",
    "        try:\n",
    "            w_mn *= -1\n",
    "            numerator += w_mn * deviations[n][a]\n",
    "            denominator += abs(w_mn)\n",
    "\n",
    "        # For the case that the neighbors of the given movie n hasn't rate the given user a\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # If the sum of weights is 0 (the sum of the similarities values = 0)\n",
    "    if denominator == 0:\n",
    "        pred = averages[m]\n",
    "    else:\n",
    "        pred = averages[m] + numerator / denominator\n",
    "\n",
    "    # The fixed range of rating is between .5 and 5\n",
    "    pred = min(5, pred)\n",
    "    pred = max(.5, pred)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(pred, actual):\n",
    "    '''\n",
    "    Calculating the loss by MSE\n",
    "    input: the list of the prediction and actual values\n",
    "    output : mean_squared_error\n",
    "    '''\n",
    "    loss = np.array(pred) - np.array(actual)\n",
    "    return np.mean(loss**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction and actual value from train set\n",
    "tr_preds = []\n",
    "tr_actual = []\n",
    "\n",
    "for (a, m), r in um_to_rating_tr.items():\n",
    "    # Predict the score of movie m by user a\n",
    "    pred = predict_scoring(a, m)\n",
    "\n",
    "    tr_preds.append(pred)\n",
    "    tr_actual.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction and actual value from test set\n",
    "te_preds = []\n",
    "te_actual = []\n",
    "\n",
    "for (a, m), r in um_to_rating_te.items():\n",
    "    # Predict the score of movie m by user a\n",
    "    pred = predict_scoring(a, m)\n",
    "\n",
    "    te_preds.append(pred)\n",
    "    te_actual.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the loss\n",
    "tr_loss = get_loss(tr_preds, tr_actual)\n",
    "tr_loss = get_loss(te_preds, te_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of train set : 0.8567\n",
      "The loss of test set :  0.8746\n"
     ]
    }
   ],
   "source": [
    "print(\"The loss of train set : %.4f\" % tr_loss)\n",
    "print(\"The loss of test set :  %.4f\" % te_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
